{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM Baseline Model\n",
    "\n",
    "make models for each route(A, B, C, D) and prediction period(predict 2 weeks ahead, 4 weeks ahead, ...)\n",
    "\n",
    "## Dateset\n",
    "- [diff value from previous day](https://github.com/hiroshi-kuriyama/rail_level_gap/issues/2) of [rolling mean over days](https://github.com/hiroshi-kuriyama/rail_level_gap/issues/4)\n",
    "## Target Variable\n",
    "- vel_l values X weeks ahead (X = 2,4,6,8)\n",
    "## Features\n",
    "\n",
    "- track variables\n",
    "  - present lev_l value\n",
    "  - mean and variance of recent lev_l value\n",
    "  - mean and variance of recent days and whole year values of track data\n",
    "- equipment variables\n",
    "  - row value of equipment variables\n",
    "- seasonal variables\n",
    "  - date (encoded by trigonometric function)\n",
    "  - holiday dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import lightgbm as lgb\n",
    "from hyperopt import hp, tpe, Trials, fmin\n",
    "%matplotlib inline\n",
    "# from utils import data_process as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '../input/'\n",
    "working_dir = '../working/'\n",
    "output_dir = '../output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_track(line_name='a'):\n",
    "    track_df = pd.read_csv(os.path.join(input_dir, 'track_{}.csv'.format(line_name.upper())))\n",
    "    col_names_track = ['date', 'kilo', 'lev_l', 'lev_r', 'cur_l', 'cur_r', 'cant', 'width', 'speed']\n",
    "    track_df.columns = col_names_track\n",
    "    track_df['date'] = pd.to_datetime(track_df['date'])\n",
    "    print('track_{line_name} shape: {shape}'.format(line_name=line_name.upper(), shape=track_df.shape))\n",
    "    return track_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleeper_type_dict = {\n",
    "    1: 'pc',\n",
    "    2: 'wooden',\n",
    "    3: 'junction',\n",
    "    4: 'short',\n",
    "    5: 'synthetic',\n",
    "    6: 'synth_junc',\n",
    "    7: 'symth_short',\n",
    "    8: 'other'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_equ(line_name='a'):\n",
    "    equ_df = pd.read_csv(os.path.join(input_dir, 'equipment_{}.csv'.format(line_name.upper())))\n",
    "    col_names_equ = ['kilo', 'is_ballast', 'is_long', 'sleeper_type', 'is_bridge', 'is_crossing', 'gross_ton', 'radius', 'is_unreliable']\n",
    "    equ_df.columns = col_names_equ\n",
    "    equ_df['sleeper_type'] = equ_df['sleeper_type'].replace(sleeper_type_dict).astype('category')\n",
    "    print('equ_{line_name} shape: {shape}'.format(line_name=line_name.upper(), shape=equ_df.shape))\n",
    "    return equ_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track_A shape: (10185690, 9)\n",
      "equ_A shape: (27906, 9)\n",
      "track_B shape: (7815753, 9)\n",
      "equ_B shape: (21531, 9)\n",
      "track_C shape: (20324660, 9)\n",
      "equ_C shape: (55684, 9)\n",
      "track_D shape: (5601687, 9)\n",
      "equ_D shape: (15691, 9)\n"
     ]
    }
   ],
   "source": [
    "abcd_list = ['a', 'b', 'c', 'd']\n",
    "track = {}\n",
    "equ = {}\n",
    "for abcd in abcd_list:\n",
    "    track[abcd] = read_track(abcd)\n",
    "    equ[abcd] = read_equ(abcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degrade data types to save memory\n",
    "def degrade_dtypes(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype=='int64':\n",
    "            df[col] = df[col].astype('int32')\n",
    "        if df[col].dtype=='float64':\n",
    "            df[col] = df[col].astype('float32')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for abcd in abcd_list:\n",
    "    track[abcd] = degrade_dtypes(track[abcd])\n",
    "    equ[abcd] = degrade_dtypes(equ[abcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "### rolling average, diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling average params\n",
    "roll_params = {\n",
    "    'A': {'window': 21, 'min_periods': 14},\n",
    "    'B': {'window': 14, 'min_periods': 7},\n",
    "    'C': {'window': 14, 'min_periods': 7},\n",
    "    'D': {'window': 14, 'min_periods': 7}\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lev_df = {}\n",
    "lev_df_ra = {}\n",
    "lev_df_ra_diff = {}\n",
    "lev_ra_diff = {}\n",
    "for abcd in abcd_list:\n",
    "    # pivot: row is date, col is kilo\n",
    "    lev_df[abcd] = track[abcd].pivot(index='date', columns='kilo', values='lev_l')\n",
    "    lev_df[abcd].columns = lev_df[abcd].columns.astype('str')\n",
    "    # rolling average\n",
    "    lev_df_ra[abcd] = lev_df[abcd].rolling(**roll_params[abcd.upper()], center=True, axis=0).mean()\n",
    "    # diff\n",
    "    lev_df_ra_diff[abcd] = lev_df_ra[abcd].diff()\n",
    "    # reverse pivot\n",
    "    lev_ra_diff[abcd] = pd.melt(lev_df_ra_diff[abcd].reset_index(), id_vars='date', value_name='lev_l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll_diff(track, abcd):\n",
    "        # pivot: row is date, col is kilo\n",
    "        lev_df = track[abcd].pivot(index='date', columns='kilo', values='lev_l')\n",
    "        lev_df.columns = lev_df.columns.astype('str')\n",
    "        # rolling average\n",
    "        lev_df_ra = lev_df.rolling(**roll_params[abcd.upper()], center=True, axis=0).mean()\n",
    "        # diff\n",
    "        lev_df_ra_diff = lev_df_ra.diff()\n",
    "        # reverse pivot\n",
    "        return pd.melt(lev_df_ra_diff.reset_index(), id_vars='date', value_name='lev_l_diff')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lev_ra_diff = {}\n",
    "for abcd in abcd_list:\n",
    "    lev_ra_diff[abcd] = roll_diff(track, abcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>kilo</th>\n",
       "      <th>lev_l_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-09</td>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-11</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.011667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-12</td>\n",
       "      <td>10000</td>\n",
       "      <td>-0.040667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-13</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   kilo  lev_l_diff\n",
       "0 2017-04-09  10000         NaN\n",
       "1 2017-04-10  10000    0.015000\n",
       "2 2017-04-11  10000    0.011667\n",
       "3 2017-04-12  10000   -0.040667\n",
       "4 2017-04-13  10000    0.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lev_ra_diff[abcd].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_whole_mean = {}\n",
    "for abcd in abcd_list:\n",
    "    track_whole_mean[abcd] = track[abcd].groupby('kilo').mean()\n",
    "    track_whole_mean[abcd].columns = [i + '_w_mean' for i in track_whole_mean[abcd].columns]\n",
    "    track_whole_mean[abcd] = track_whole_mean[abcd].reset_index()\n",
    "    track_whole_mean[abcd]['kilo'] = track_whole_mean[abcd]['kilo'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lev_ra_diff_tgt = {}\n",
    "for abcd in abcd_list:\n",
    "    lev_ra_diff_tgt_tmp = lev_ra_diff[abcd].copy()\n",
    "#     lev_ra_diff_tgt_tmp = lev_ra_diff_tgt_tmp.rename({'lev_l_diff': 'lev_l_diff_tgt'})\n",
    "    lev_ra_diff_tgt_tmp['date_tgt'] = lev_ra_diff_tgt_tmp['date']\n",
    "    lev_ra_diff_tgt_tmp['date'] = lev_ra_diff_tgt_tmp['date'] - datetime.timedelta(weeks=2)\n",
    "    lev_ra_diff_tgt_tmp = lev_ra_diff_tgt_tmp.rename(columns={'lev_l_diff': 'lev_l_diff_tgt'})\n",
    "    lev_ra_diff_tgt[abcd] = lev_ra_diff_tgt_tmp\n",
    "    \n",
    "del lev_ra_diff_tgt_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>kilo</th>\n",
       "      <th>lev_l_diff_tgt</th>\n",
       "      <th>date_tgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-03-26</td>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-03-27</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>2017-04-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-03-28</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.011667</td>\n",
       "      <td>2017-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-03-29</td>\n",
       "      <td>10000</td>\n",
       "      <td>-0.040667</td>\n",
       "      <td>2017-04-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-03-30</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2017-04-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   kilo  lev_l_diff_tgt   date_tgt\n",
       "0 2017-03-26  10000             NaN 2017-04-09\n",
       "1 2017-03-27  10000        0.015000 2017-04-10\n",
       "2 2017-03-28  10000        0.011667 2017-04-11\n",
       "3 2017-03-29  10000       -0.040667 2017-04-12\n",
       "4 2017-03-30  10000        0.000000 2017-04-13"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lev_ra_diff_tgt[abcd].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = {}\n",
    "for abcd in abcd_list:\n",
    "    # copy target df\n",
    "    data_all_tmp = lev_ra_diff_tgt[abcd].copy()\n",
    "    # merge features\n",
    "    data_all_tmp = data_all_tmp.merge(lev_ra_diff[abcd], on=['date', 'kilo'])\n",
    "    data_all_tmp = data_all_tmp.merge(track_whole_mean[abcd], on='kilo')\n",
    "\n",
    "    data_all_tmp['line_name'] = abcd.upper()\n",
    "    data_all[abcd] = data_all_tmp\n",
    "    \n",
    "del lev_ra_diff_tgt, lev_ra_diff, track_whole_mean, data_all_tmp, track, equ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# union\n",
    "data_u_all = pd.concat([data_all[abcd] for abcd in abcd_list], axis=0)\n",
    "data_u_all['line_name'] = data_u_all['line_name'].astype('category')\n",
    "del data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_u_all.to_pickle(os.path.join(input_dir, 'data_u_all_lgbm_baseline.pkl'))\n",
    "data_u_all = pd.read_pickle(os.path.join(input_dir, 'data_u_all_lgbm_baseline.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_u_all = data_u_all.dropna(how='any', axis=0, subset=['lev_l_diff_tgt', 'lev_l_diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_y_split(data, tgt_col='lev_l_diff_tgt', index_cols=['date', 'date_tgt', 'kilo']):\n",
    "    data = data.set_index(index_cols)\n",
    "    y = data[tgt_col]\n",
    "    X = data.drop(tgt_col, axis=1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test\n",
    "threshold_date = '2018-01-01'\n",
    "X_dev, y_dev = X_y_split(data_u_all.query('date<\"{}\"'.format(threshold_date)))\n",
    "X_val, y_val = X_y_split(data_u_all.query('date>\"{}\"'.format(threshold_date)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperopt_params = {\n",
    "    'num_leaves': hp.uniform('num_leaves', 500, 700),\n",
    "    'min_child_samples': hp.uniform('min_child_samples', 200, 300),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.05, 0.2),\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.5, 0.7),\n",
    "    'bagging_freq': hp.uniform('bagging_freq', 6, 8)\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{'bagging_freq': 7,\n",
    " 'feature_fraction': 0.6570918110525219,\n",
    " 'learning_rate': 0.15106159518328655,\n",
    " 'min_child_samples': 266,\n",
    " 'num_leaves': 607}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params = {\n",
    "    'early_stopping_rounds':20,\n",
    "    'eval_set':[(X_val, y_val)],\n",
    "    'eval_metric': 'mean_absolute_error',\n",
    "    'verbose': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# float to int\n",
    "tobe_int_params = ['num_leaves', 'min_child_samples', 'bagging_freq']\n",
    "def int_param_encoder(params):\n",
    "    for param in tobe_int_params:\n",
    "        if param in params:\n",
    "            params[param] = int(params[param])\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_evals_i = 0\n",
    "def objective(hyperopt_params):\n",
    "    # パラメータを適切な型(int)に変換\n",
    "    hyperopt_params = int_param_encoder(hyperopt_params)\n",
    "    # モデルのインスタンス化\n",
    "    model = lgb.LGBMRegressor(**hyperopt_params, objective='mean_absolute_error', n_estimators=1000, random_state=0)\n",
    "    # trainデータを使ってモデルの学習\n",
    "    model.fit(X_dev, y_dev, **fit_params)\n",
    "    # validationデータを使用して、ラベルの予測\n",
    "    y_val_pred = model.predict(X_val, num_iteration=model.best_iteration_)\n",
    "    # 予測ラベルと正解ラベルを使用してMAEを計算\n",
    "    mae_score = mean_absolute_error(y_val, y_val_pred)\n",
    "    global num_evals_i\n",
    "    num_evals_i += 1\n",
    "    print('[{num_evals}] best_ite: {best_ite}\\tMAE: {mae_score}'.format(num_evals=str(num_evals_i).zfill(4), mae_score=mae_score, best_ite=model.best_iteration_))\n",
    "    return mae_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterationする回数\n",
    "max_evals = 10\n",
    "# 試行の過程を記録するインスタンス\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(\n",
    "    # 最小化する値を定義した関数\n",
    "    fn=objective,\n",
    "    # 探索するパラメータのdictもしくはlist\n",
    "    space=hyperopt_params,\n",
    "    # どのロジックを利用するか、基本的にはtpe.suggestでok\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=max_evals,\n",
    "    trials=trials,\n",
    "    # 試行の過程を出力\n",
    "    verbose=-1,\n",
    "    rstate=np.random.RandomState(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_freq': 7,\n",
       " 'feature_fraction': 0.6570918110525219,\n",
       " 'learning_rate': 0.15106159518328655,\n",
       " 'min_child_samples': 266,\n",
       " 'num_leaves': 607}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_param_encoder(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_freq=7, boosting_type='gbdt', class_weight=None,\n",
       "       colsample_bytree=1.0, feature_fraction=0.6570918110525219,\n",
       "       importance_type='split', learning_rate=0.15106159518328655,\n",
       "       max_depth=-1, min_child_samples=266, min_child_weight=0.001,\n",
       "       min_split_gain=0.0, n_estimators=10, n_jobs=-1, num_leaves=607,\n",
       "       objective=None, random_state=0, reg_alpha=0.0, reg_lambda=0.0,\n",
       "       silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "       subsample_freq=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X_dev, y_dev, X_val, y_val\n",
    "# make submission\n",
    "best_params = int_param_encoder(best)\n",
    "X, y = X_y_split(data_u_all)\n",
    "model_fulldata = lgb.LGBMRegressor(**best_params, n_estimators=10, random_state=0)\n",
    "model_fulldata.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最後から2週間の値の平均値を入力としてモデルで2週間後の数値を予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>kilo</th>\n",
       "      <th>lev_l_diff_tgt</th>\n",
       "      <th>date_tgt</th>\n",
       "      <th>lev_l_diff</th>\n",
       "      <th>lev_l_w_mean</th>\n",
       "      <th>lev_r_w_mean</th>\n",
       "      <th>cur_l_w_mean</th>\n",
       "      <th>cur_r_w_mean</th>\n",
       "      <th>cant_w_mean</th>\n",
       "      <th>width_w_mean</th>\n",
       "      <th>speed_w_mean</th>\n",
       "      <th>line_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.021520</td>\n",
       "      <td>2017-04-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.330575</td>\n",
       "      <td>-0.679421</td>\n",
       "      <td>0.101544</td>\n",
       "      <td>0.221274</td>\n",
       "      <td>0.281081</td>\n",
       "      <td>3.711467</td>\n",
       "      <td>65.766129</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>10000</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>2017-04-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.330575</td>\n",
       "      <td>-0.679421</td>\n",
       "      <td>0.101544</td>\n",
       "      <td>0.221274</td>\n",
       "      <td>0.281081</td>\n",
       "      <td>3.711467</td>\n",
       "      <td>65.766129</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>10000</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.330575</td>\n",
       "      <td>-0.679421</td>\n",
       "      <td>0.101544</td>\n",
       "      <td>0.221274</td>\n",
       "      <td>0.281081</td>\n",
       "      <td>3.711467</td>\n",
       "      <td>65.766129</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>10000</td>\n",
       "      <td>-0.040526</td>\n",
       "      <td>2017-04-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.330575</td>\n",
       "      <td>-0.679421</td>\n",
       "      <td>0.101544</td>\n",
       "      <td>0.221274</td>\n",
       "      <td>0.281081</td>\n",
       "      <td>3.711467</td>\n",
       "      <td>65.766129</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-05</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.005789</td>\n",
       "      <td>2017-04-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.330575</td>\n",
       "      <td>-0.679421</td>\n",
       "      <td>0.101544</td>\n",
       "      <td>0.221274</td>\n",
       "      <td>0.281081</td>\n",
       "      <td>3.711467</td>\n",
       "      <td>65.766129</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   kilo  lev_l_diff_tgt   date_tgt  lev_l_diff  lev_l_w_mean  \\\n",
       "0 2017-04-01  10000        0.021520 2017-04-15         NaN     -1.330575   \n",
       "1 2017-04-02  10000       -0.007368 2017-04-16         NaN     -1.330575   \n",
       "2 2017-04-03  10000       -0.007368 2017-04-17         NaN     -1.330575   \n",
       "3 2017-04-04  10000       -0.040526 2017-04-18         NaN     -1.330575   \n",
       "4 2017-04-05  10000        0.005789 2017-04-19         NaN     -1.330575   \n",
       "\n",
       "   lev_r_w_mean  cur_l_w_mean  cur_r_w_mean  cant_w_mean  width_w_mean  \\\n",
       "0     -0.679421      0.101544      0.221274     0.281081      3.711467   \n",
       "1     -0.679421      0.101544      0.221274     0.281081      3.711467   \n",
       "2     -0.679421      0.101544      0.221274     0.281081      3.711467   \n",
       "3     -0.679421      0.101544      0.221274     0.281081      3.711467   \n",
       "4     -0.679421      0.101544      0.221274     0.281081      3.711467   \n",
       "\n",
       "   speed_w_mean line_name  \n",
       "0     65.766129         A  \n",
       "1     65.766129         A  \n",
       "2     65.766129         A  \n",
       "3     65.766129         A  \n",
       "4     65.766129         A  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_u_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_tmp = data_u_all.groupby(['line_name', 'kilo'])['date_tgt'].max()\n",
    "\n",
    "last_date_values_df = index_tmp.reset_index()\n",
    "last_date_values_df = last_date_values_df.merge(data_u_all, how='left', on=['line_name', 'kilo', 'date_tgt'])\n",
    "last_date_values_df['date'] = last_date_values_df['date_tgt']\n",
    "last_date_values_df['lev_l_diff'] = last_date_values_df['lev_l_diff_tgt']\n",
    "last_date_values_df = last_date_values_df[['line_name', 'kilo', 'date', 'lev_l_diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_f, y_pred_f_tmp = X_y_split(last_date_values_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_f = model_fulldata.predict(X_pred_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_name</th>\n",
       "      <th>kilo</th>\n",
       "      <th>date</th>\n",
       "      <th>lev_l_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>10000</td>\n",
       "      <td>2018-03-15</td>\n",
       "      <td>-0.252524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>10001</td>\n",
       "      <td>2018-03-15</td>\n",
       "      <td>-0.201143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>10002</td>\n",
       "      <td>2018-03-15</td>\n",
       "      <td>-0.137143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>10003</td>\n",
       "      <td>2018-03-15</td>\n",
       "      <td>-0.081667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>10004</td>\n",
       "      <td>2018-03-15</td>\n",
       "      <td>-0.032190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  line_name   kilo       date  lev_l_diff\n",
       "0         A  10000 2018-03-15   -0.252524\n",
       "1         A  10001 2018-03-15   -0.201143\n",
       "2         A  10002 2018-03-15   -0.137143\n",
       "3         A  10003 2018-03-15   -0.081667\n",
       "4         A  10004 2018-03-15   -0.032190"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_date_values_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
